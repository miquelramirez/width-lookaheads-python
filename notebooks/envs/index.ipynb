{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```WalkBot-v0``` \n",
    "\n",
    "WalkBot with Discrete Actions, Reward is shortest path, [notebook](walkbot_v0.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```WalkBot-v1```\n",
    "\n",
    "WalkBot with Discrete Actions, reward is shortest path, terminal states are absorbing, [notebook](walkbot_v1.ipyng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ```WalkBot-v2```\n",
    "WalkBot with Discrete Actions, reward is QR cost \n",
    "\n",
    "$$\n",
    "Q = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0\\\\\n",
    "0 & 1 & 0 & 0\\\\\n",
    "0 & 0 & 1 & 0\\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{bmatrix},\\, \n",
    "R = \\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "NB: control $u$ is fixed per each action\n",
    "\n",
    "[Notebook](walkbot_v2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```WalkBot-v3```\n",
    "\n",
    "As above, but with perturbation $w_t$ defined as follows\n",
    "\n",
    "$$\n",
    "w_t = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\mathcal{N}(0,\\sigma_{vx}^2)\\\\\n",
    "\\mathcal{N}(0,\\sigma_{vy}^2)\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "[Notebook](walkbot_v3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WalkBot-RandomInit-v0\n",
    "\n",
    "Like ```WalkBot-v2```, but with initial random state\n",
    "\n",
    "$$\n",
    "x_0 = \\begin{bmatrix}\n",
    "\\mathcal{N}(5, 2)\\\\\n",
    "\\mathcal{N}(5, 2)\\\\\n",
    "\\mathcal{N}(0.05, 2)\\\\\n",
    "\\mathcal{N}(0.05, 2)\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notebook](walkbot_random_init_v0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WalkBot-RandomInit-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like ```WalkBot-v3``` but randominsing the initial state $x_0$ as ```WalkBot-RandomInit-v0``` does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notebook](walkbot_random_init_v1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ContinuousWalkBot-v0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} \n",
    "x \\\\ \n",
    "y \\\\ \n",
    "v_x \\\\ \n",
    "v_y\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "control\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\begin{bmatrix}\n",
    "a_x \\\\\n",
    "a_y\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subject to constraints\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " 0 \\leq x \\leq 10 \\\\\n",
    " 0 \\leq y \\leq 10 \\\\\n",
    " -10 \\leq v_x \\leq 10 \\\\\n",
    " -10 \\leq v_y \\leq 10 \\\\\n",
    " -2 \\leq a_x \\leq 2 \\\\\n",
    " -2 \\leq a_y \\leq 2 \\\\\n",
    " v_{x}^2 + v_{y}^2 \\geq 0.01\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and cost function\n",
    "\n",
    "$$\n",
    "Q = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0\\\\\n",
    "0 & 1 & 0 & 0\\\\\n",
    "0 & 0 & 1 & 0\\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{bmatrix},\\, \n",
    "R = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State matrix\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input matrix\n",
    "\n",
    "$$\n",
    "B = \\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notebook with model demonstration](continuous_walkbot_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Notebook with Baseline Policies](continuous_walkbot_v0.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ContinuousWalkBot-v1\n",
    "\n",
    "Task has same definition as ```ContinuousWalkBot-v1```, but adds noise to actual velocities in the same way ```WalkBot-v3``` does.\n",
    "\n",
    "[Notebook](continuous_walkbot_v1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ContinuousWalkBot-RandomInit-v0\n",
    "\n",
    "Task is like ```ContinuousWalkBot-v0``` but with random initial states.\n",
    "\n",
    "[Notebook](continuous_walkbot_random_init_v0.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ContinuousWalkBot-RandomInit-v1\n",
    "\n",
    "Task is like ```ContinuousWalkBot-v1``` but with random initial states\n",
    "\n",
    "[Notebook](continuous_walkbot_random_init_v1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```ContinuousMountainCar-v1``` \n",
    "Continuous Mountain Car with QR cost as rewards, [notebook](mountain_car_continuous_v1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ``Hard'' Reinforcement Learning domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ```RechtLQR-v0```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benjamin Recht's LQR benchmark ``Simple HVAC'' [problem](http://argmin.net/2018/05/11/coarse-id-control/). Applying random control will lead the servers temperature to grow exponentially very quickly.\n",
    "\n",
    "[Notebook](recht_lqr_v0.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Antishape-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John Langford's _Antishape_ [domain](https://github.com/JohnLangford/RL_acid). Here's the description of the problem:\n",
    "\n",
    "If rewards in the vicinity of a start state favor\n",
    "staying near a start state, then reward values far from the start\n",
    "state are irrelevant.  The name comes from \"reward shaping\" which is\n",
    "typically used to make RL easier.  Here, we use it to make RL harder.\n",
    "\n",
    "[Notebook](antishape_v1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combolock-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John Langford's _Combolock_ [domain](https://github.com/JohnLangford/RL_acid). Here's his description of the problem:\n",
    "\n",
    "When most actions lead towards the start state\n",
    "uniform random exploration is relatively useless.  The name comes\n",
    "from \"combination lock\" where knowing the right sequence of steps to\n",
    "take is the problem.\n",
    "\n",
    "[Notebook](combolock_v1.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
